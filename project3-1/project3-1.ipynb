{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "5cba3963c37d400916a9e80ad5acd0c56daed180f4961ad2a064f19bb9bbda97"
   }
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Project: Creditworthiness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [13, 13]"
   ]
  },
  {
   "source": [
    "## Step 1: Business and Data Understanding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load past applications\n",
    "past_applications = pd.read_excel('credit-data-training.xlsx')\n",
    "new_customers = pd.read_excel('customers-to-score.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "past_applications.head()"
   ]
  },
  {
   "source": [
    "### Key Decisions:\n",
    "\n",
    "* What decisions needs to be made?\n",
    "  * I need to evaluate the creditworthiness of the new 500 loan applicants.\n",
    "\n",
    "* What data is needed to inform those decisions?\n",
    "  * I need past loan applicant's information on credit application results and the data used to rate those results like Duration of credit, credit amount, installment, age of the applicant, etc.\n",
    "\n",
    "* What kind of model (Continuous, Binary, Non-Binary, Time-Series) do we need to use to help make these decisions?\n",
    "  * The model type will be Binary as I will be predicting an applicant to be either creditworthy or non-creditworthy.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Step 2: Building the Training Set\n",
    "\n",
    "### Guidelines:\n",
    "* For numerical data fields, are there any fields that highly-correlate with each other? The correlation should be at least .70 to be considered “high”.\n",
    "* Are there any missing data for each of the data fields? Fields with a lot of missing data should be removed\n",
    "* Are there only a few values in a subset of your data field? Does the data field look very uniform (there is only one value for the entire field?). This is called “low variability” and you should remove fields that have low variability. Refer to the \"Tips\" section to find examples of data fields with low-variability.\n",
    "*Your clean data set should have 13 columns where the Average of Age Years should be 36 (rounded up)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables Non Null Count\n",
    "past_applications.info()\n",
    "\n",
    "columns_to_drop = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missing values\n",
    "print('Counting Missing Values')\n",
    "past_applications.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Vizualization\n",
    "fig, axes = plt.subplots(4,5, figsize=(23, 23))\n",
    "x = list(past_applications.columns)\n",
    "\n",
    "for i, column in enumerate(past_applications.columns):\n",
    "    if past_applications[column].dtype == np.dtype('O'):\n",
    "        past_applications[column].value_counts().plot(kind='bar', rot=0, ax=axes[int(i/5)][i%5]).set_title(column)\n",
    "    else:\n",
    "        past_applications[column].hist(ax=axes[int(i/5)][i%5]).set_title(column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop Duration-in-Current-address due to many missing data\n",
    "columns_to_drop.append('Duration-in-Current-address')\n",
    "# drop Concurrent-Credits due to low variability\n",
    "columns_to_drop.append('Concurrent-Credits')\n",
    "# drop Occupation due to low variability\n",
    "columns_to_drop.append('Occupation')\n",
    "\n",
    "# drop due to low variability\n",
    "columns_to_drop.append('Guarantors')\n",
    "columns_to_drop.append('Telephone')\n",
    "columns_to_drop.append('No-of-dependents')\n",
    "columns_to_drop.append('Foreign-Worker')\n",
    "\n",
    "clean_data = past_applications.drop(columns=columns_to_drop)\n",
    "\n",
    "past_applications[columns_to_drop].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Removed Vizualization\n",
    "fig, axes = plt.subplots(2,4, figsize=(15, 9))\n",
    "\n",
    "for i, column in enumerate(columns_to_drop):\n",
    "    if past_applications[column].dtype == np.dtype('O'):\n",
    "        past_applications[column].value_counts().plot(kind='bar', rot=0, ax=axes[int(i/4)][i%4]).set_title(column)\n",
    "    else:\n",
    "        past_applications[column].hist(ax=axes[int(i/4)][i%4]).set_title(column)\n",
    "\n",
    "# fig.savefig('droped_variables_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median\n",
    "clean_data = clean_data.fillna(clean_data.median())\n",
    "clean_data.describe().round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation\n",
    "clean_data.corr().round(2)"
   ]
  },
  {
   "source": [
    "### Answer this question:\n",
    "\n",
    "* In your cleanup process, which fields did you remove or impute? Please justify why you removed or imputed these fields. Visualizations are encouraged.\n",
    "  * The imputed field is Age-years, There 12 applicants with empty age data. I can not remove these applicants as I will lose 2.4% of the data. I will fill all empty data with an age median of 33.\n",
    "  * I will remove all fields with low variability to remove bias in my model. The removed fields are:\n",
    "    - Duration in a current address\n",
    "    - Concurrent credits\n",
    "    - Occupation\n",
    "    - Guarantors\n",
    "    - Telephone\n",
    "    - No of dependents\n",
    "    - Foreign worker"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Step 3: Train your Classification Models\n",
    "\n",
    "First, create your Estimation and Validation samples where 70% of your dataset should go to Estimation and 30% of your entire dataset should be reserved for Validation. Set the Random Seed to 1.\n",
    "\n",
    "Create all of the following models: Logistic Regression, Decision Tree, Forest Model, Boosted Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace target to binary\n",
    "target_column = 'Credit-Application-Result'\n",
    "target_label = ['Creditworthy', 'Non-Creditworthy'] # list(clean_data[target_column].unique())\n",
    "clean_data[target_column].replace({'Creditworthy': 1, 'Non-Creditworthy': 0}, inplace=True)\n",
    "\n",
    "# Categorical Columns\n",
    "categorical_columns = ['Account-Balance', 'Payment-Status-of-Previous-Credit', 'Purpose', 'Value-Savings-Stocks',  'Length-of-current-employment',  'No-of-Credits-at-this-Bank'] # clean_data.select_dtypes(include='O')\n",
    "\n",
    "# Numerical Columns\n",
    "numerical_columns = ['Duration-of-Credit-Month', 'Credit-Amount', 'Instalment-per-cent', 'Most-valuable-available-asset', 'Age-years', 'Type-of-apartment'] # clean_data.select_dtypes(exclude='O')\n",
    "\n",
    "# get target and predictors from cleaned dataframe\n",
    "def get_predictors_target(df):\n",
    "    target = None\n",
    "    if target_column in df.columns:\n",
    "        target = df[target_column]\n",
    "    predictors = df[numerical_columns+categorical_columns]\n",
    "    return predictors, target\n",
    "\n",
    "# Preprocessing Data for Models\n",
    "transformer = ColumnTransformer(\n",
    "    [\n",
    "        ('scaler' , StandardScaler(), numerical_columns),\n",
    "        ('encoder', OneHotEncoder(drop='first'), categorical_columns)\n",
    "    ], \n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Training Data\n",
    "X, y = get_predictors_target(clean_data)\n",
    "\n",
    "# fit data to create features\n",
    "transformer.fit(X)\n",
    "\n",
    "# split trainging data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=1)\n",
    "\n",
    "# Features after scaler and encoder\n",
    "feature_names = numerical_columns + list(transformer.transformers_[1][1].get_feature_names(categorical_columns))\n",
    "\n",
    "print('Features Name:', feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model - stasmodels\n",
    "sm_logReg = sm.Logit(y_train, transformer.transform(X_train)).fit(maxiter=1000)\n",
    "y_hat = list(map(round, sm_logReg.predict(transformer.transform(X_test))))\n",
    "\n",
    "cm = metrics.confusion_matrix(y_true=y_test, y_pred=y_hat)\n",
    "print(sm_logReg.summary2(xname=feature_names))\n",
    "\n",
    "print('Confusion Matrix')\n",
    "_, ax = plt.subplots(figsize=(6,5))\n",
    "fig_ = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_label[::-1])\n",
    "fig_.plot(ax=ax)\n",
    "plt.show()\n",
    "\n",
    "print('\\nAccuracy on Training Data: ', metrics.accuracy_score(y_test, y_hat), '\\n')\n",
    "print('Report\\n', metrics.classification_report(y_true=y_test, y_pred=y_hat))"
   ]
  },
  {
   "source": [
    "### Decision Tree Model - GridSearch\n",
    "\n",
    "### Find best parameters\n",
    "`parameters = {'criterion': ['gini', 'entropy'], 'splitter': ['best', 'random'], 'max_depth': range(1,20)}`\n",
    "\n",
    "`decision_tree_grid = GridSearchCV(DecisionTreeClassifier(), param_grid=parameters, scoring='precision', cv=10, n_jobs=-1)`\n",
    "\n",
    "`decision_tree_grid.fit(transformer.transform(X_train), y_train)`\n",
    "\n",
    "`decision_tree_grid.best_params_`\n",
    "\n",
    "- Best params: {'criterion': 'gini', 'max_depth': 13, 'splitter': 'random'}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Model\n",
    "decision_tree_model = DecisionTreeClassifier(criterion='gini', max_depth=13, splitter='random')\n",
    "decision_tree_model.fit(transformer.transform(X_train), y_train)\n",
    "\n",
    "# Features Impotances\n",
    "feature_importances_dtm = pd.Series(decision_tree_model.feature_importances_, index=feature_names).sort_values()\n",
    "print('\\nFeatures Impotances Plot')\n",
    "feature_importances_dtm.plot(kind='barh', figsize=(7,6))\n",
    "plt.show()\n",
    "\n",
    "print('\\nConfusion Matrix')\n",
    "_, ax = plt.subplots(figsize=(6,5))\n",
    "metrics.plot_confusion_matrix(decision_tree_model, transformer.transform(X_test), y_test, ax=ax, display_labels=target_label[::-1])\n",
    "plt.show()\n",
    "\n",
    "print('\\nAccuracy on Training Data: ', decision_tree_model.score(transformer.transform(X_test), y_test), '\\n')\n",
    "print('Report\\n' ,metrics.classification_report(y_test, decision_tree_model.predict(transformer.transform(X_test))))\n"
   ]
  },
  {
   "source": [
    "### Forest Model Model - GridSearch\n",
    "\n",
    "### Find best parameters\n",
    "`parameters = {'n_estimators': range(50, 1100, 25),'criterion': ['gini', 'entropy'], 'max_depth': range(1,20)}`\n",
    "\n",
    "`random_forest_grid = GridSearchCV(RandomForestClassifier(), param_grid=parameters, scoring='precision', cv=10, n_jobs=-1)`\n",
    "\n",
    "`random_forest_grid.fit(transformer.transform(X_train), y_train)`\n",
    "\n",
    "`random_forest_grid.best_params_`\n",
    "\n",
    "- Best params: {'criterion': 'gini', 'max_depth': 16, 'n_estimators': 100}\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forest Model Model\n",
    "random_forest_model = RandomForestClassifier(criterion='gini', max_depth=16, n_estimators=100)\n",
    "random_forest_model.fit(transformer.transform(X_train), y_train)\n",
    "\n",
    "# Features Impotances\n",
    "feature_importances_rfm = pd.Series(random_forest_model.feature_importances_, index=feature_names).sort_values()\n",
    "print('\\nFeatures Impotances Plot')\n",
    "feature_importances_rfm.plot(kind='barh', figsize=(7,6))\n",
    "plt.show()\n",
    "\n",
    "print('\\nConfusion Matrix')\n",
    "_, ax = plt.subplots(figsize=(6,5))\n",
    "metrics.plot_confusion_matrix(random_forest_model, transformer.transform(X_test), y_test, ax=ax, display_labels=target_label[::-1])\n",
    "plt.show()\n",
    "\n",
    "print('\\nAccuracy on Training Data: ', random_forest_model.score(transformer.transform(X_test), y_test), '\\n')\n",
    "print('Report\\n', metrics.classification_report(y_test, random_forest_model.predict(transformer.transform(X_test))))"
   ]
  },
  {
   "source": [
    "### AdaBoost Model - GridSearch\n",
    "\n",
    "### Find best parameters\n",
    "`parameters = {'n_estimators': range(50, 1100, 100), 'algorithm': ['SAMME', 'SAMME.R'], 'learning_rate': np.arange(.1, 1.1, .1)}`\n",
    "\n",
    "`ada_boost_grid = GridSearchCV(AdaBoostClassifier(), param_grid=parameters, scoring='precision', cv=10, n_jobs=-1)`\n",
    "\n",
    "`ada_boost_grid.fit(transformer.transform(X_train), y_train)`\n",
    "\n",
    "`ada_boost_grid.best_params_`\n",
    "\n",
    "- Best params: {'algorithm': 'SAMME.R', 'learning_rate': 0.8, 'n_estimators': 150}"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosted Tree Model\n",
    "ada_boost_model = AdaBoostClassifier(n_estimators=150, algorithm='SAMME.R', learning_rate=0.8)\n",
    "ada_boost_model.fit(transformer.transform(X_train), y_train)\n",
    "\n",
    "# Features Impotances\n",
    "feature_importances_btm = pd.Series(ada_boost_model.feature_importances_, index=feature_names).sort_values()\n",
    "print('\\nFeatures Impotances Plot')\n",
    "feature_importances_btm.plot(kind='barh', figsize=(7,6))\n",
    "plt.show()\n",
    "\n",
    "print('\\nConfusion Matrix')\n",
    "_, ax = plt.subplots(figsize=(6,5))\n",
    "metrics.plot_confusion_matrix(ada_boost_model, transformer.transform(X_test), y_test, ax=ax, display_labels=target_label[::-1])\n",
    "plt.show()\n",
    "\n",
    "print('\\nAccuracy on Training Data: ', ada_boost_model.score(transformer.transform(X_test), y_test), '\\n')\n",
    "print('Report\\n' ,metrics.classification_report(y_test, ada_boost_model.predict(transformer.transform(X_test)), target_names=target_label[::-1]))"
   ]
  },
  {
   "source": [
    "### Answer these questions for each model you created:\n",
    "\n",
    "* Which predictor variables are significant or the most important? Please show the p-values or variable importance charts for all of your predictor variables.\n",
    "\n",
    "* Validate your model against the Validation set. What was the overall percent accuracy? Show the confusion matrix. Are there any bias seen in the model’s predictions? \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Step 4: Writeup\n",
    "\n",
    "Decide on the best model and score your new customers. For reviewing consistency, if Score_Creditworthy is greater than Score_NonCreditworthy, the person should be labeled as “Creditworthy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Model Selected\n",
    "ada_boost_model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepair new customers data for prediction\n",
    "data_to_predict, _ = get_predictors_target(new_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc plot\n",
    "_, ax = plt.subplots(figsize=(8,7))\n",
    "# plot roc curve for statsmodles\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, list(map(round, sm_logReg.predict(transformer.transform(X_test)))))\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc)\n",
    "display.plot(ax=ax, name='Logistic Regression Model')\n",
    "\n",
    "metrics.plot_roc_curve(decision_tree_model, transformer.transform(X_test), y_test, name ='Decison Tree Model', ax=ax)\n",
    "metrics.plot_roc_curve(random_forest_model, transformer.transform(X_test), y_test, name ='Forest Model', ax=ax)\n",
    "metrics.plot_roc_curve(ada_boost_model, transformer.transform(X_test), y_test, name ='Boosted Model', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict New Customers - Logistic Regression\n",
    "predicted = np.array(list(map(round, sm_logReg.predict(transformer.transform(data_to_predict)))))\n",
    "\n",
    "# count predection\n",
    "creditworthy_count = (predicted == 1).sum()\n",
    "non_creditworthy_count = (predicted == 0).sum()\n",
    "print('Creditworthy applicants: ', creditworthy_count)\n",
    "print('Non Creditworthy applicants: ', non_creditworthy_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict New Customers - Decision Tree\n",
    "predicted = decision_tree_model.predict(transformer.transform(data_to_predict))\n",
    "\n",
    "# count predection\n",
    "creditworthy_count = (predicted == 1).sum()\n",
    "non_creditworthy_count = (predicted == 0).sum()\n",
    "print('Creditworthy applicants: ', creditworthy_count)\n",
    "print('Non Creditworthy applicants: ', non_creditworthy_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict New Customers - Forest\n",
    "predicted = random_forest_model.predict(transformer.transform(data_to_predict))\n",
    "\n",
    "# count predection\n",
    "creditworthy_count = (predicted == 1).sum()\n",
    "non_creditworthy_count = (predicted == 0).sum()\n",
    "print('Creditworthy applicants: ', creditworthy_count)\n",
    "print('Non Creditworthy applicants: ', non_creditworthy_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict New Customers - Boost\n",
    "predicted = ada_boost_model.predict(transformer.transform(data_to_predict))\n",
    "\n",
    "# count predection\n",
    "creditworthy_count = (predicted == 1).sum()\n",
    "non_creditworthy_count = (predicted == 0).sum()\n",
    "print('Creditworthy applicants: ', creditworthy_count)\n",
    "print('Non Creditworthy applicants: ', non_creditworthy_count)"
   ]
  },
  {
   "source": [
    "### Answer these questions\n",
    "* Which model did you choose to use? \n",
    "* How many individuals are creditworthy?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}