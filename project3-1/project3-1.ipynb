{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Project: Creditworthiness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "\n",
    "# plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = [11, 7]"
   ]
  },
  {
   "source": [
    "## Step 1: Business and Data Understanding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Key Decisions:\n",
    "\n",
    "* What decisions needs to be made?\n",
    "\n",
    "* What data is needed to inform those decisions?\n",
    "\n",
    "* What kind of model (Continuous, Binary, Non-Binary, Time-Series) do we need to use to help make these decisions?\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Step 2: Building the Training Set\n",
    "\n",
    "### Guidelines:\n",
    "* For numerical data fields, are there any fields that highly-correlate with each other? The correlation should be at least .70 to be considered “high”.\n",
    "* Are there any missing data for each of the data fields? Fields with a lot of missing data should be removed\n",
    "* Are there only a few values in a subset of your data field? Does the data field look very uniform (there is only one value for the entire field?). This is called “low variability” and you should remove fields that have low variability. Refer to the \"Tips\" section to find examples of data fields with low-variability.\n",
    "*Your clean data set should have 13 columns where the Average of Age Years should be 36 (rounded up)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Answer this question:\n",
    "\n",
    "* In your cleanup process, which fields did you remove or impute? Please justify why you removed or imputed these fields. Visualizations are encouraged.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Step 3: Train your Classification Models\n",
    "\n",
    "First, create your Estimation and Validation samples where 70% of your dataset should go to Estimation and 30% of your entire dataset should be reserved for Validation. Set the Random Seed to 1.\n",
    "\n",
    "Create all of the following models: Logistic Regression, Decision Tree, Forest Model, Boosted Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Answer these questions for each model you created:\n",
    "\n",
    "* Which predictor variables are significant or the most important? Please show the p-values or variable importance charts for all of your predictor variables.\n",
    "\n",
    "* Validate your model against the Validation set. What was the overall percent accuracy? Show the confusion matrix. Are there any bias seen in the model’s predictions? \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Step 4: Writeup\n",
    "\n",
    "Decide on the best model and score your new customers. For reviewing consistency, if Score_Creditworthy is greater than Score_NonCreditworthy, the person should be labeled as “Creditworthy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Answer these questions\n",
    "* Which model did you choose to use? \n",
    "* How many individuals are creditworthy?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}